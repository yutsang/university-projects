{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loc</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>shipNo</th>\n",
       "      <th>origLoc</th>\n",
       "      <th>destLoc</th>\n",
       "      <th>planStartTime</th>\n",
       "      <th>planEndTime</th>\n",
       "      <th>actStartTime</th>\n",
       "      <th>actEndTime</th>\n",
       "      <th>MiscTime</th>\n",
       "      <th>planDurn</th>\n",
       "      <th>actDurn</th>\n",
       "      <th>ActDurn-nonNull</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>sysCode</th>\n",
       "      <th>companyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHN</td>\n",
       "      <td>NO-LIMIT</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>000182436</td>\n",
       "      <td>31.31611, 121.11576</td>\n",
       "      <td>30.93646, 121.46803</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017-02-07 01:01:28</td>\n",
       "      <td>2019-01-16 22:04:04</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>0 days 01:01:28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.017965e+06</td>\n",
       "      <td>CHN</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHN</td>\n",
       "      <td>NO-LIMIT</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>000182584</td>\n",
       "      <td>31.31611, 121.11576</td>\n",
       "      <td>30.93646, 121.46803</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017-02-07 01:01:28</td>\n",
       "      <td>2019-01-16 22:04:04</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>0 days 01:01:28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.017965e+06</td>\n",
       "      <td>CHN</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHN</td>\n",
       "      <td>NO-LIMIT</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>000183341</td>\n",
       "      <td>31.31611, 121.11576</td>\n",
       "      <td>30.93646, 121.46803</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017-02-07 01:01:28</td>\n",
       "      <td>2019-01-16 22:04:04</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>0 days 01:01:28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.017965e+06</td>\n",
       "      <td>CHN</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHN</td>\n",
       "      <td>NO-LIMIT</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>000183345</td>\n",
       "      <td>31.31611, 121.11576</td>\n",
       "      <td>30.93646, 121.46803</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017-02-07 01:01:28</td>\n",
       "      <td>2019-01-16 22:04:04</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>0 days 01:01:28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.017965e+06</td>\n",
       "      <td>CHN</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHN</td>\n",
       "      <td>NO-LIMIT</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>000183763</td>\n",
       "      <td>31.31611, 121.11576</td>\n",
       "      <td>30.93646, 121.46803</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>2017-02-07 01:01:28</td>\n",
       "      <td>2019-01-16 22:04:04</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>2017-02-08 23:59:00</td>\n",
       "      <td>0 days 01:01:28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-1.017965e+06</td>\n",
       "      <td>CHN</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loc   Vehicle warehouse     shipNo              origLoc  \\\n",
       "0  CHN  NO-LIMIT      TSX0  000182436  31.31611, 121.11576   \n",
       "1  CHN  NO-LIMIT      TSX0  000182584  31.31611, 121.11576   \n",
       "2  CHN  NO-LIMIT      TSX0  000183341  31.31611, 121.11576   \n",
       "3  CHN  NO-LIMIT      TSX0  000183345  31.31611, 121.11576   \n",
       "4  CHN  NO-LIMIT      TSX0  000183763  31.31611, 121.11576   \n",
       "\n",
       "               destLoc planStartTime         planEndTime        actStartTime  \\\n",
       "0  30.93646, 121.46803    2017-02-07 2017-02-07 01:01:28 2019-01-16 22:04:04   \n",
       "1  30.93646, 121.46803    2017-02-07 2017-02-07 01:01:28 2019-01-16 22:04:04   \n",
       "2  30.93646, 121.46803    2017-02-07 2017-02-07 01:01:28 2019-01-16 22:04:04   \n",
       "3  30.93646, 121.46803    2017-02-07 2017-02-07 01:01:28 2019-01-16 22:04:04   \n",
       "4  30.93646, 121.46803    2017-02-07 2017-02-07 01:01:28 2019-01-16 22:04:04   \n",
       "\n",
       "           actEndTime            MiscTime        planDurn actDurn  \\\n",
       "0 2017-02-08 23:59:00 2017-02-08 23:59:00 0 days 01:01:28     NaT   \n",
       "1 2017-02-08 23:59:00 2017-02-08 23:59:00 0 days 01:01:28     NaT   \n",
       "2 2017-02-08 23:59:00 2017-02-08 23:59:00 0 days 01:01:28     NaT   \n",
       "3 2017-02-08 23:59:00 2017-02-08 23:59:00 0 days 01:01:28     NaT   \n",
       "4 2017-02-08 23:59:00 2017-02-08 23:59:00 0 days 01:01:28     NaT   \n",
       "\n",
       "   ActDurn-nonNull countryCode sysCode companyCode  \n",
       "0    -1.017965e+06         CHN     TMS         LFL  \n",
       "1    -1.017965e+06         CHN     TMS         LFL  \n",
       "2    -1.017965e+06         CHN     TMS         LFL  \n",
       "3    -1.017965e+06         CHN     TMS         LFL  \n",
       "4    -1.017965e+06         CHN     TMS         LFL  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import datetime64\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "#from sqlalchemy import null\n",
    "from numpy import datetime64\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import folium\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import difflib\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "check_file_name = \"raw_clean_osm_phl_all.csv\"\n",
    "final_file_name = \"raw_merge_osm_weather_phl_all.csv\"\n",
    "weather_file_name = \"weather_phl_2019_2023.csv\"\n",
    "\n",
    "# Define Hong Kong's boundary polygon using its latitude and longitude coordinates\n",
    "hong_kong_boundary = Polygon([\n",
    "  (4.2257, 116.1262),\n",
    "  (4.2257, 126.6082),\n",
    "  (21.1209, 126.6082),\n",
    "  (21.1209, 116.1262),\n",
    "  (4.2257, 116.1262)\n",
    "])\n",
    "location = \"PHL\"\n",
    "load_graph_place = \"Philippines\"\n",
    "\n",
    "#from folium.features import DivIcon\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "hwy_speeds = {\"residential\": 10, \"secondary\": 33, \"tertiary\": 60}\n",
    "\n",
    "dir = os.getcwd()\n",
    "#Do not need to change the folder name\n",
    "folder_name = \"ETA-Prediction\"\n",
    "\n",
    "#Change filename for different regions or datasets\n",
    "filename = \"eta_prediction.csv\"\n",
    "#df_HKG.csv is a processed file that only extract HK data from the eta-prediction.csv\n",
    "\n",
    "path = dir[:dir.find(folder_name)]+folder_name+\"-Data/1.Data/\" + filename\n",
    "\n",
    "\n",
    "#from folium.features import DivIcon\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df_backup = pd.read_csv(\"eta_prediction.csv\")\n",
    "df = df_backup\n",
    "\n",
    "df.columns = [\"Loc\", \"Vehicle\", \"ShipNo\", \"Start-Lng\", \"Start-Lat\", \"Dest-Lng\", \"Dest-Lat\", \n",
    "    \"Time-1\", \"Time-2\", \"Time-3\", \"Time-4\", \"Time-5\"]\n",
    "\n",
    "for i in range(5):\n",
    "    column = \"Time-\"+ str(i+1)\n",
    "    df[column] = pd.to_datetime(df[column], errors = 'coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "convert_dict = {\"Loc\": str, \"Vehicle\": str, \"ShipNo\": str, \"Start-Lng\": str, \"Start-Lat\": str, \"Dest-Lng\": str, \"Dest-Lat\": str,\n",
    "    \"Time-5\": datetime64, \"Time-5\": datetime64, \"Time-5\": datetime64, \"Time-5\": datetime64, \"Time-5\": datetime64}\n",
    "df = df.astype(convert_dict)\n",
    "\n",
    "df[\"planDurn\"] = df[\"Time-2\"].dropna()-df[\"Time-1\"].dropna()\n",
    "df[\"actDurn\"] = df[\"Time-4\"].dropna()-df[\"Time-3\"].dropna()\n",
    "df[\"Time-4\"] = df[\"Time-4\"].fillna(df[\"Time-5\"])\n",
    "df[\"ActDurn-nonNull\"] = (df[\"Time-4\"].dropna()-df[\"Time-3\"].dropna()).dt.total_seconds()/60\n",
    "#df[\"ActDurn-nonNull\"] = df[\"actDurn-nonNull\"].dt.total_seconds()\n",
    "#df[\"plannedRemainTime\"] = df[\"Time-5\"].dropna().astype(datetime64)-df[\"Time-2\"].dropna().astype(datetime64)\n",
    "#df[\"actualRemainTime\"] = df[\"Time-5\"].dropna().astype(datetime64)-df[\"Time-4\"].dropna().astype(datetime64)\n",
    "\n",
    "df['companyCode'] = df['ShipNo'].str[:3]\n",
    "df['sysCode'] = df['ShipNo'].str[:7].str[4:]\n",
    "df['countryCode'] = df['ShipNo'].str[:11].str[8:]\n",
    "df['warehouse'] = df['ShipNo'].str[:16].str[12:]\n",
    "df['shipNo'] = df['ShipNo'].str[-9:]\n",
    "\n",
    "\n",
    "\n",
    "df = df.rename({\"Time-1\": \"planStartTime\", \"Time-2\": \"planEndTime\", \"Time-3\": \"actStartTime\", \n",
    "    \"Time-4\": \"actEndTime\", \"Time-5\": \"MiscTime\"}, axis = \"columns\")\n",
    "\n",
    "df[\"origLoc\"] = df[[\"Start-Lng\", \"Start-Lat\"]].agg(', '.join, axis=1)\n",
    "df[\"destLoc\"] = df[[\"Dest-Lng\", \"Dest-Lat\"]].agg(', '.join, axis=1)\n",
    "df = df.drop([\"Start-Lng\", \"Start-Lat\", \"Dest-Lng\", \"Dest-Lat\", 'ShipNo'], axis=1)\n",
    "\n",
    "cols = [\"Loc\", \"Vehicle\", \"warehouse\", \"shipNo\", \"origLoc\", \"destLoc\", \"planStartTime\", \"planEndTime\", \"actStartTime\", \"actEndTime\", \n",
    "    \"MiscTime\", \"planDurn\", \"actDurn\", \"ActDurn-nonNull\", \"countryCode\", \"sysCode\", \"companyCode\"]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loc</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>shipNo</th>\n",
       "      <th>origLoc</th>\n",
       "      <th>destLoc</th>\n",
       "      <th>planStartTime</th>\n",
       "      <th>planEndTime</th>\n",
       "      <th>actStartTime</th>\n",
       "      <th>actEndTime</th>\n",
       "      <th>MiscTime</th>\n",
       "      <th>planDurn</th>\n",
       "      <th>actDurn</th>\n",
       "      <th>ActDurn-nonNull</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>sysCode</th>\n",
       "      <th>companyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3237859</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591908]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.75247, 120.96951</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 18:23:25</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 20:59:33</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 18:23:25</td>\n",
       "      <td>0 days 20:59:33</td>\n",
       "      <td>1259.550000</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237893</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591909, 002591918, 002591923, 002591929, 0...</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.75247, 120.96951</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 20:50:25</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 22:49:06</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 20:50:25</td>\n",
       "      <td>0 days 22:49:06</td>\n",
       "      <td>1369.100000</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237892</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591945, 002591948]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.43873, 121.04671</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 21:38:54</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 18:21:50</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 21:38:54</td>\n",
       "      <td>0 days 18:21:50</td>\n",
       "      <td>1101.833333</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237856</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591907]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.43873, 121.04671</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 22:58:54</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 21:39:32</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 22:58:54</td>\n",
       "      <td>0 days 21:39:32</td>\n",
       "      <td>1299.533333</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237864</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591926, 002591912]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.48245, 121.05771</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 01:14:09</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 22:39:55</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>1 days 01:14:09</td>\n",
       "      <td>0 days 22:39:55</td>\n",
       "      <td>1359.916667</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Loc Vehicle warehouse  \\\n",
       "3237859  PHL    10WH      TSX0   \n",
       "3237893  PHL    10WH      TSX0   \n",
       "3237892  PHL    10WH      TSX0   \n",
       "3237856  PHL    10WH      TSX0   \n",
       "3237864  PHL    10WH      TSX0   \n",
       "\n",
       "                                                    shipNo  \\\n",
       "3237859                                        [002591908]   \n",
       "3237893  [002591909, 002591918, 002591923, 002591929, 0...   \n",
       "3237892                             [002591945, 002591948]   \n",
       "3237856                                        [002591907]   \n",
       "3237864                             [002591926, 002591912]   \n",
       "\n",
       "                     origLoc              destLoc planStartTime  \\\n",
       "3237859  14.58673, 121.11063  14.75247, 120.96951    2019-10-02   \n",
       "3237893  14.58673, 121.11063  14.75247, 120.96951    2019-10-02   \n",
       "3237892  14.58673, 121.11063  14.43873, 121.04671    2019-10-02   \n",
       "3237856  14.58673, 121.11063  14.43873, 121.04671    2019-10-02   \n",
       "3237864  14.58673, 121.11063  14.48245, 121.05771    2019-10-02   \n",
       "\n",
       "                planEndTime actStartTime          actEndTime  \\\n",
       "3237859 2019-10-02 18:23:25   2019-10-02 2019-10-02 20:59:33   \n",
       "3237893 2019-10-02 20:50:25   2019-10-02 2019-10-02 22:49:06   \n",
       "3237892 2019-10-02 21:38:54   2019-10-02 2019-10-02 18:21:50   \n",
       "3237856 2019-10-02 22:58:54   2019-10-02 2019-10-02 21:39:32   \n",
       "3237864 2019-10-03 01:14:09   2019-10-02 2019-10-02 22:39:55   \n",
       "\n",
       "                   MiscTime        planDurn         actDurn  ActDurn-nonNull  \\\n",
       "3237859 2019-10-03 23:59:00 0 days 18:23:25 0 days 20:59:33      1259.550000   \n",
       "3237893 2019-10-03 23:59:00 0 days 20:50:25 0 days 22:49:06      1369.100000   \n",
       "3237892 2019-10-03 23:59:00 0 days 21:38:54 0 days 18:21:50      1101.833333   \n",
       "3237856 2019-10-03 23:59:00 0 days 22:58:54 0 days 21:39:32      1299.533333   \n",
       "3237864 2019-10-03 23:59:00 1 days 01:14:09 0 days 22:39:55      1359.916667   \n",
       "\n",
       "        countryCode sysCode companyCode  \n",
       "3237859         PHL     TMS         LFL  \n",
       "3237893         PHL     TMS         LFL  \n",
       "3237892         PHL     TMS         LFL  \n",
       "3237856         PHL     TMS         LFL  \n",
       "3237864         PHL     TMS         LFL  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic cleaning #before (4965694, 17)\n",
    "df = df[df[\"actDurn\"].notnull() & (df[\"ActDurn-nonNull\"] >= 0)]\n",
    "\n",
    "startDate = df[\"planStartTime\"].dt.strftime(\"%Y-%m-%d\").min() #\"2017-02-07\"\n",
    "endDate = df[\"planStartTime\"].dt.strftime(\"%Y-%m-%d\").max() #\"2021-12-31\"\n",
    "#change these two strings\n",
    "\n",
    "#df_hkg = df\n",
    "df_hkg = df[df[\"Loc\"] == location]\n",
    "df_hkg = df_hkg[(df_hkg['planStartTime'] >= startDate) & (df_hkg['planStartTime'] <= endDate)]\n",
    "#df_hkg.head() #(79578, 17)\n",
    "#df_hkg = df\n",
    "\n",
    "def primary_sort(df, columns_sort:list, duplicate_list:list, target_column: str):\n",
    "\n",
    "    true_list = []\n",
    "\n",
    "    for i in range(len(columns_sort)):\n",
    "        true_list.append(True)\n",
    "\n",
    "    df.sort_values(by=columns_sort, inplace=True, ascending = true_list)\n",
    "\n",
    "    df['is_duplicated'] = df.duplicated(subset=duplicate_list)\n",
    "\n",
    "    index = 0\n",
    "    df[\"is_duplicated_index\"] = 0\n",
    "    shipNoDict = {}\n",
    "    shipNoDictKey = []\n",
    "    checker = False\n",
    "\n",
    "    target_column_dummy = target_column+\"_dummy\"\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        shipNoDictKey.append(row[target_column])\n",
    "        if row[\"is_duplicated\"] == False:\n",
    "            df.loc[idx, \"is_duplicated_index\"] += index\n",
    "            shipNoDict.update({index: shipNoDictKey})\n",
    "            index += 1\n",
    "            shipNoDictKey=[]\n",
    "        elif row[\"is_duplicated\"] == True:\n",
    "            df.loc[idx, \"is_duplicated_index\"] = -1\n",
    "        \n",
    "    result = df[df[\"is_duplicated_index\"]!=-1]\n",
    "    result[target_column_dummy] = result['is_duplicated_index'].map(shipNoDict)\n",
    "\n",
    "    cols = result.columns\n",
    "    '''cols = ['Loc', 'Vehicle', 'warehouse', 'ship_no', 'origLoc', 'destLoc',\n",
    "       'planStartTime', 'planEndTime', 'actStartTime', 'actEndTime',\n",
    "       'MiscTime', 'planDurn', 'actDurn', 'ActDurn-nonNull', 'planTaskTime', 'actTaskTime',\n",
    "       'countryCode', 'sysCode', 'companyCode', 'is_duplicated',\n",
    "       'is_duplicated_index', 'shipNo']'''\n",
    "    \n",
    "    cols = list(map(lambda x: x.replace(target_column, target_column_dummy), cols))\n",
    "    #cols = [(target_column_dummy if (target_column in s) else s) for s in cols]\n",
    "    cols[-1] = target_column\n",
    "\n",
    "    result = result[cols]\n",
    "    result = result.drop(columns=cols[-3:])\n",
    "\n",
    "    result = result.rename(columns={target_column_dummy: target_column})\n",
    "    \n",
    "    return result\n",
    "\n",
    "sortList = ['Loc', 'Vehicle', 'warehouse', 'origLoc', 'planStartTime', 'planEndTime', 'actStartTime', 'actEndTime']\n",
    "duplicateList = ['Loc', 'Vehicle', 'warehouse', 'origLoc', 'destLoc', 'planStartTime', 'actStartTime', 'actEndTime']\n",
    "targetCol = 'shipNo'\n",
    "df_merge = primary_sort(df_hkg, sortList, duplicateList, targetCol)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loc</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>shipNo</th>\n",
       "      <th>origLoc</th>\n",
       "      <th>destLoc</th>\n",
       "      <th>planStartTime</th>\n",
       "      <th>planEndTime</th>\n",
       "      <th>actStartTime</th>\n",
       "      <th>actEndTime</th>\n",
       "      <th>MiscTime</th>\n",
       "      <th>planDurn</th>\n",
       "      <th>actDurn</th>\n",
       "      <th>ActDurn-nonNull</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>sysCode</th>\n",
       "      <th>companyCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3237859</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591908]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.75247, 120.96951</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 18:23:25</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 20:59:33</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 18:23:25</td>\n",
       "      <td>0 days 20:59:33</td>\n",
       "      <td>1259.550000</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237893</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591909, 002591918, 002591923, 002591929, 0...</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.75247, 120.96951</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 20:50:25</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 22:49:06</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 20:50:25</td>\n",
       "      <td>0 days 22:49:06</td>\n",
       "      <td>1369.100000</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237892</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591945, 002591948]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.43873, 121.04671</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 21:38:54</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 18:21:50</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 21:38:54</td>\n",
       "      <td>0 days 18:21:50</td>\n",
       "      <td>1101.833333</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237856</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591907]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.43873, 121.04671</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 22:58:54</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 21:39:32</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 22:58:54</td>\n",
       "      <td>0 days 21:39:32</td>\n",
       "      <td>1299.533333</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237864</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>[002591926, 002591912]</td>\n",
       "      <td>14.58673, 121.11063</td>\n",
       "      <td>14.48245, 121.05771</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 01:14:09</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02 22:39:55</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>1 days 01:14:09</td>\n",
       "      <td>0 days 22:39:55</td>\n",
       "      <td>1359.916667</td>\n",
       "      <td>PHL</td>\n",
       "      <td>TMS</td>\n",
       "      <td>LFL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Loc Vehicle warehouse  \\\n",
       "3237859  PHL    10WH      TSX0   \n",
       "3237893  PHL    10WH      TSX0   \n",
       "3237892  PHL    10WH      TSX0   \n",
       "3237856  PHL    10WH      TSX0   \n",
       "3237864  PHL    10WH      TSX0   \n",
       "\n",
       "                                                    shipNo  \\\n",
       "3237859                                        [002591908]   \n",
       "3237893  [002591909, 002591918, 002591923, 002591929, 0...   \n",
       "3237892                             [002591945, 002591948]   \n",
       "3237856                                        [002591907]   \n",
       "3237864                             [002591926, 002591912]   \n",
       "\n",
       "                     origLoc              destLoc planStartTime  \\\n",
       "3237859  14.58673, 121.11063  14.75247, 120.96951    2019-10-02   \n",
       "3237893  14.58673, 121.11063  14.75247, 120.96951    2019-10-02   \n",
       "3237892  14.58673, 121.11063  14.43873, 121.04671    2019-10-02   \n",
       "3237856  14.58673, 121.11063  14.43873, 121.04671    2019-10-02   \n",
       "3237864  14.58673, 121.11063  14.48245, 121.05771    2019-10-02   \n",
       "\n",
       "                planEndTime actStartTime          actEndTime  \\\n",
       "3237859 2019-10-02 18:23:25   2019-10-02 2019-10-02 20:59:33   \n",
       "3237893 2019-10-02 20:50:25   2019-10-02 2019-10-02 22:49:06   \n",
       "3237892 2019-10-02 21:38:54   2019-10-02 2019-10-02 18:21:50   \n",
       "3237856 2019-10-02 22:58:54   2019-10-02 2019-10-02 21:39:32   \n",
       "3237864 2019-10-03 01:14:09   2019-10-02 2019-10-02 22:39:55   \n",
       "\n",
       "                   MiscTime        planDurn         actDurn  ActDurn-nonNull  \\\n",
       "3237859 2019-10-03 23:59:00 0 days 18:23:25 0 days 20:59:33      1259.550000   \n",
       "3237893 2019-10-03 23:59:00 0 days 20:50:25 0 days 22:49:06      1369.100000   \n",
       "3237892 2019-10-03 23:59:00 0 days 21:38:54 0 days 18:21:50      1101.833333   \n",
       "3237856 2019-10-03 23:59:00 0 days 22:58:54 0 days 21:39:32      1299.533333   \n",
       "3237864 2019-10-03 23:59:00 1 days 01:14:09 0 days 22:39:55      1359.916667   \n",
       "\n",
       "        countryCode sysCode companyCode  \n",
       "3237859         PHL     TMS         LFL  \n",
       "3237893         PHL     TMS         LFL  \n",
       "3237892         PHL     TMS         LFL  \n",
       "3237856         PHL     TMS         LFL  \n",
       "3237864         PHL     TMS         LFL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def primary_sort(df, columns_sort:list, duplicate_list:list, target_column: str):\n",
    "\n",
    "    true_list = []\n",
    "\n",
    "    for i in range(len(columns_sort)):\n",
    "        true_list.append(True)\n",
    "\n",
    "    df.sort_values(by=columns_sort, inplace=True, ascending = true_list)\n",
    "\n",
    "    df['is_duplicated'] = df.duplicated(subset=duplicate_list)\n",
    "\n",
    "    index = 0\n",
    "    df[\"is_duplicated_index\"] = 0\n",
    "    shipNoDict = {}\n",
    "    shipNoDictKey = []\n",
    "    checker = False\n",
    "\n",
    "    target_column_dummy = target_column+\"_dummy\"\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        shipNoDictKey.append(row[target_column])\n",
    "        if row[\"is_duplicated\"] == False:\n",
    "            df.loc[idx, \"is_duplicated_index\"] += index\n",
    "            shipNoDict.update({index: shipNoDictKey})\n",
    "            index += 1\n",
    "            shipNoDictKey=[]\n",
    "        elif row[\"is_duplicated\"] == True:\n",
    "            df.loc[idx, \"is_duplicated_index\"] = -1\n",
    "        \n",
    "    result = df[df[\"is_duplicated_index\"]!=-1]\n",
    "    result[target_column_dummy] = result['is_duplicated_index'].map(shipNoDict)\n",
    "\n",
    "    cols = result.columns\n",
    "    '''cols = ['Loc', 'Vehicle', 'warehouse', 'ship_no', 'origLoc', 'destLoc',\n",
    "       'planStartTime', 'planEndTime', 'actStartTime', 'actEndTime',\n",
    "       'MiscTime', 'planDurn', 'actDurn', 'ActDurn-nonNull', 'planTaskTime', 'actTaskTime',\n",
    "       'countryCode', 'sysCode', 'companyCode', 'is_duplicated',\n",
    "       'is_duplicated_index', 'shipNo']'''\n",
    "    \n",
    "    cols = list(map(lambda x: x.replace(target_column, target_column_dummy), cols))\n",
    "    #cols = [(target_column_dummy if (target_column in s) else s) for s in cols]\n",
    "    cols[-1] = target_column\n",
    "\n",
    "    result = result[cols]\n",
    "    result = result.drop(columns=cols[-3:])\n",
    "\n",
    "    result = result.rename(columns={target_column_dummy: target_column})\n",
    "    \n",
    "    return result\n",
    "\n",
    "sortList = ['Loc', 'Vehicle', 'warehouse', 'origLoc', 'planStartTime', 'planEndTime', 'actStartTime', 'actEndTime']\n",
    "duplicateList = ['Loc', 'Vehicle', 'warehouse', 'origLoc', 'destLoc', 'planStartTime', 'actStartTime', 'actEndTime']\n",
    "targetCol = 'shipNo'\n",
    "df_merge = primary_sort(df_hkg, sortList, duplicateList, targetCol)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17360, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primary_list: [columns] agg_col: columns to be aggregated to the new df\n",
    "def drop_duplicate(df, primary_lists:list, sort_only_col:str, agg_col:str):\n",
    "    ascend_boolean = []\n",
    "    sorting_list = primary_lists.remove(sort_only_col)\n",
    "    print(sorting_list)\n",
    "    for item in range(len(sorting_list)):\n",
    "        ascend_boolean.append(True)\n",
    "    df.sort_values(sorting_list, axis=0, ascending=ascend_boolean, inplace=True, na_position=\"first\")\n",
    "    col_name = list(df.columns.values)\n",
    "    col_loc = col_name.index(agg_col)\n",
    "\n",
    "    agg_col_cloned = agg_col+\"_index\"\n",
    "    \n",
    "    df['is_duplicated'] = df.duplicated(subset=primary_lists)\n",
    "    \n",
    "    index = 0\n",
    "    df[\"is_duplicated_index\"] = 0\n",
    "    shipNoDict = {}\n",
    "    shipNoDictKey = []\n",
    "    checker = False\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        shipNoDictKey.append(row[agg_col])\n",
    "        if row[\"is_duplicated\"] == False:\n",
    "            df.loc[idx, \"is_duplicated_index\"] += index\n",
    "            shipNoDict.update({index: shipNoDictKey})\n",
    "            index += 1\n",
    "            shipNoDictKey=[]\n",
    "        elif row[\"is_duplicated\"] == True:\n",
    "            df.loc[idx, \"is_duplicated_index\"] += -1\n",
    "        \n",
    "    df = df[df[\"is_duplicated_index\"]!=-1]\n",
    "    df[agg_col_cloned] = df['is_duplicated_index'].map(shipNoDict)\n",
    "    #df = df.drop([\"is_duplicated\", \"is_duplicated_index\", agg_col], axis=1)\n",
    "    col_name[col_loc] = agg_col_cloned\n",
    "    df = df[col_name]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hkg_cleansed = drop_duplicate(df_hkg, ['Loc', 'Vehicle', 'warehouse', 'origLoc', 'destLoc', 'planStartTime', 'planEndTime', 'actStartTime', 'actEndTime'], 'destLoc', 'shipNo')\n",
    "df_hkg_cleansed = df_hkg[df_hkg['is_duplicated_index']!=-1]\n",
    "\n",
    "raw = df_hkg_cleansed.reset_index()\n",
    "raw[\"sameRoute\"] = raw.duplicated(subset=[\"Loc\", \"Vehicle\", \"warehouse\", \"origLoc\", \"planStartTime\", \"planEndTime\", \"actStartTime\", \"actEndTime\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17360, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loc</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>shipNo</th>\n",
       "      <th>Route</th>\n",
       "      <th>planStartTime</th>\n",
       "      <th>actStartTime</th>\n",
       "      <th>MiscTime</th>\n",
       "      <th>planDurn</th>\n",
       "      <th>actDurn</th>\n",
       "      <th>ActDurn-nonNull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>002591908</td>\n",
       "      <td>[14.58673, 121.11063, 14.75247, 120.96951]</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 18:23:25</td>\n",
       "      <td>0 days 20:59:33</td>\n",
       "      <td>1259.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>002591942</td>\n",
       "      <td>[14.58673, 121.11063, 14.75247, 120.96951]</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 20:50:25</td>\n",
       "      <td>0 days 22:49:06</td>\n",
       "      <td>1369.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>002591948</td>\n",
       "      <td>[14.58673, 121.11063, 14.43873, 121.04671]</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 21:38:54</td>\n",
       "      <td>0 days 18:21:50</td>\n",
       "      <td>1101.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>002591907</td>\n",
       "      <td>[14.58673, 121.11063, 14.43873, 121.04671]</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>0 days 22:58:54</td>\n",
       "      <td>0 days 21:39:32</td>\n",
       "      <td>1299.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHL</td>\n",
       "      <td>10WH</td>\n",
       "      <td>TSX0</td>\n",
       "      <td>002591912</td>\n",
       "      <td>[14.58673, 121.11063, 14.48245, 121.05771]</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2019-10-03 23:59:00</td>\n",
       "      <td>1 days 01:14:09</td>\n",
       "      <td>0 days 22:39:55</td>\n",
       "      <td>1359.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loc Vehicle warehouse     shipNo  \\\n",
       "0  PHL    10WH      TSX0  002591908   \n",
       "1  PHL    10WH      TSX0  002591942   \n",
       "2  PHL    10WH      TSX0  002591948   \n",
       "3  PHL    10WH      TSX0  002591907   \n",
       "4  PHL    10WH      TSX0  002591912   \n",
       "\n",
       "                                        Route planStartTime actStartTime  \\\n",
       "0  [14.58673, 121.11063, 14.75247, 120.96951]    2019-10-02   2019-10-02   \n",
       "1  [14.58673, 121.11063, 14.75247, 120.96951]    2019-10-02   2019-10-02   \n",
       "2  [14.58673, 121.11063, 14.43873, 121.04671]    2019-10-02   2019-10-02   \n",
       "3  [14.58673, 121.11063, 14.43873, 121.04671]    2019-10-02   2019-10-02   \n",
       "4  [14.58673, 121.11063, 14.48245, 121.05771]    2019-10-02   2019-10-02   \n",
       "\n",
       "             MiscTime        planDurn         actDurn  ActDurn-nonNull  \n",
       "0 2019-10-03 23:59:00 0 days 18:23:25 0 days 20:59:33      1259.550000  \n",
       "1 2019-10-03 23:59:00 0 days 20:50:25 0 days 22:49:06      1369.100000  \n",
       "2 2019-10-03 23:59:00 0 days 21:38:54 0 days 18:21:50      1101.833333  \n",
       "3 2019-10-03 23:59:00 0 days 22:58:54 0 days 21:39:32      1299.533333  \n",
       "4 2019-10-03 23:59:00 1 days 01:14:09 0 days 22:39:55      1359.916667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest = []\n",
    "route = []\n",
    "for index, row in raw.iterrows():\n",
    "    if index < len(raw):\n",
    "        if index == 0: \n",
    "            route.append(row[\"origLoc\"])\n",
    "            route.append(row[\"destLoc\"])\n",
    "        if row[\"sameRoute\"] == False and index != 0: #start a new row\n",
    "            #if route[0]!= route[-1]: route.append(route[0])\n",
    "            dest.append(route)\n",
    "            route = []\n",
    "            route.append(row[\"origLoc\"])\n",
    "            route.append(row[\"destLoc\"])\n",
    "        if row[\"sameRoute\"]: \n",
    "            if row[\"destLoc\"]!= route[-1]: route.append(row[\"destLoc\"])\n",
    "    if index == len(raw) -1: \n",
    "        #route.append(route[0])\n",
    "        dest.append(route)\n",
    "\n",
    "df_dest = pd.DataFrame({\"Route\":dest}).reset_index()\n",
    "raw_clean = raw[raw[\"sameRoute\"]==False]\n",
    "raw_clean = raw_clean.reset_index()\n",
    "df_dest = pd.DataFrame({\"Route\":dest})\n",
    "raw_clean[\"Route\"] = df_dest\n",
    "\n",
    "raw_clean = raw_clean[[\"Loc\", \"Vehicle\", \"warehouse\", \"shipNo\", \"Route\", \"planStartTime\", \"actStartTime\",\n",
    "                             \"MiscTime\", \"planDurn\", \"actDurn\", \"ActDurn-nonNull\"]]\n",
    "raw_clean.head() #(2733, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12422, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loc Vehicle warehouse     shipNo  \\\n",
      "0  PHL    10WH      TSX0  002591908   \n",
      "1  PHL    10WH      TSX0  002591942   \n",
      "2  PHL    10WH      TSX0  002591948   \n",
      "3  PHL    10WH      TSX0  002591907   \n",
      "4  PHL    10WH      TSX0  002591912   \n",
      "\n",
      "                                        Route planStartTime actStartTime  \\\n",
      "0  [14.58673, 121.11063, 14.75247, 120.96951]    2019-10-02   2019-10-02   \n",
      "1  [14.58673, 121.11063, 14.75247, 120.96951]    2019-10-02   2019-10-02   \n",
      "2  [14.58673, 121.11063, 14.43873, 121.04671]    2019-10-02   2019-10-02   \n",
      "3  [14.58673, 121.11063, 14.43873, 121.04671]    2019-10-02   2019-10-02   \n",
      "4  [14.58673, 121.11063, 14.48245, 121.05771]    2019-10-02   2019-10-02   \n",
      "\n",
      "             MiscTime        planDurn         actDurn  ActDurn-nonNull  \n",
      "0 2019-10-03 23:59:00 0 days 18:23:25 0 days 20:59:33      1259.550000  \n",
      "1 2019-10-03 23:59:00 0 days 20:50:25 0 days 22:49:06      1369.100000  \n",
      "2 2019-10-03 23:59:00 0 days 21:38:54 0 days 18:21:50      1101.833333  \n",
      "3 2019-10-03 23:59:00 0 days 22:58:54 0 days 21:39:32      1299.533333  \n",
      "4 2019-10-03 23:59:00 1 days 01:14:09 0 days 22:39:55      1359.916667  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8576 entries, 0 to 12421\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype          \n",
      "---  ------           --------------  -----          \n",
      " 0   Loc              8576 non-null   object         \n",
      " 1   Vehicle          8576 non-null   object         \n",
      " 2   warehouse        8576 non-null   object         \n",
      " 3   shipNo           8576 non-null   object         \n",
      " 4   Route            8576 non-null   object         \n",
      " 5   planStartTime    8576 non-null   datetime64[ns] \n",
      " 6   actStartTime     8576 non-null   datetime64[ns] \n",
      " 7   MiscTime         8571 non-null   datetime64[ns] \n",
      " 8   planDurn         8576 non-null   timedelta64[ns]\n",
      " 9   actDurn          8576 non-null   timedelta64[ns]\n",
      " 10  ActDurn-nonNull  8576 non-null   float64        \n",
      "dtypes: datetime64[ns](3), float64(1), object(5), timedelta64[ns](2)\n",
      "memory usage: 3.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#further clean -> believe in normal case journey time would be less than 5 days\n",
    "raw_clean = raw_clean[raw_clean[\"ActDurn-nonNull\"] < 5*24*60]\n",
    "print(raw_clean.head()) #(1682, 11)\n",
    "print(raw_clean.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8576, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test HKG only\n",
    "raw_clean = raw_clean[raw_clean['Loc']== location]\n",
    "raw_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================================\n",
    "#============================Direct Copy from main.ipynb below this line============================\n",
    "#===================================================================================================\n",
    "#===================================================================================================\n",
    "#===================================================================================================\n",
    "#==================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loadGraph(place=\"HK\", optimizer=\"travel_time\", mode = \"drive\", hwy_speeds=hwy_speeds):\n",
    "    #ox.config(log_console = True, use_cache = True)\n",
    "    ##mode = 'drive' # 'drive', 'bike', 'walk'\n",
    "    #graph = ox.graph_from_place(place, network_type = mode)\n",
    "    #graph = ox.add_edge_speeds(graph, hwy_speeds)\n",
    "    #graph = ox.add_edge_travel_times(graph)\n",
    "    #return graph\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import osmnx as ox\n",
    "\n",
    "#not in use\n",
    "def loadGraph_v1(graphml_file=\"hongkong_speed.graphml\"):\n",
    "    # load the street network and the saved edge speeds from the GraphML file\n",
    "    ox.config(log_console = True, use_cache = True)\n",
    "    #mode = 'drive' # 'drive', 'bike', 'walk'\n",
    "    graph = ox.graph_from_place(\"HK\", network_type = 'drive')\n",
    "    # Define the file paths for the TomTom speed data\n",
    "    rush_hour_path = './tomtom_speeds_weekday_rush_hours.json'\n",
    "    non_rush_hour_path = './tomtom_speeds_weekday_non_rush_hours.json'\n",
    "\n",
    "    # Define the start and end times for the two rush hour intervals\n",
    "    rush_start_time_am = datetime.time(7, 0)   # Rush hour in the morning starts at 7:00 AM\n",
    "    rush_end_time_am = datetime.time(10, 0)    # Rush hour in the morning ends at 10:00 AM\n",
    "    rush_start_time_pm = datetime.time(16, 0)  # Rush hour in the afternoon starts at 4:00 PM\n",
    "    rush_end_time_pm = datetime.time(19, 0)    # Rush hour in the afternoon ends at 7:00 PM\n",
    "\n",
    "    # Define a dictionary to store the speed data as well as the rush hour classification\n",
    "    speed_data = {}\n",
    "\n",
    "    # Load the TomTom speed data into the dictionary for rush hour\n",
    "    print('Loading', rush_hour_path)\n",
    "    with open(rush_hour_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            start_time_str = data.get('startTime')\n",
    "            if start_time_str:\n",
    "                start_time = datetime.datetime.strptime(start_time_str, '%Y-%m-%dT%H:%M:%S').time()\n",
    "                osm_id = data.get('frc', '') + str(data.get('id', ''))\n",
    "                speed = data.get('currentSpeed', '')\n",
    "                if osm_id and speed:\n",
    "                    if rush_start_time_am <= start_time <= rush_end_time_am:\n",
    "                        if osm_id not in speed_data:\n",
    "                            speed_data[osm_id] = {'speed': speed, 'rush_hour': 'am'}\n",
    "                        else:\n",
    "                            speed_data[osm_id]['rush_hour'] = 'both'\n",
    "                    elif rush_start_time_pm <= start_time <= rush_end_time_pm:\n",
    "                        if osm_id not in speed_data:\n",
    "                            speed_data[osm_id] = {'speed': speed, 'rush_hour': 'pm'}\n",
    "                        else:\n",
    "                            speed_data[osm_id]['rush_hour'] = 'both'\n",
    "\n",
    "    # Load the TomTom speed data into the dictionary for non-rush hour\n",
    "    print('Loading', non_rush_hour_path)\n",
    "    with open(non_rush_hour_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            start_time_str = data.get('startTime')\n",
    "            if start_time_str:\n",
    "                osm_id = data.get('frc', '') + str(data.get('id', ''))\n",
    "                speed = data.get('currentSpeed', '')\n",
    "                if osm_id and speed:\n",
    "                    if osm_id not in speed_data:\n",
    "                        speed_data[osm_id] = {'speed': speed, 'rush_hour': 'none'}\n",
    "                    else:\n",
    "                        speed_data[osm_id]['rush_hour'] = 'none'\n",
    "\n",
    "    # Load the street network from OpenStreetMap for Hong Kong\n",
    "    print('Loading street network')\n",
    "    #place_name = 'Hong Kong, China'\n",
    "    #G = ox.graph_from_place(place_name, network_type='drive')\n",
    "\n",
    "    # Assign the speed data to the edges in the street network\n",
    "    print('Assigning speed data to edges')\n",
    "    ox.speed.add_edge_speeds(graph, speed_data)\n",
    "    ox.speed.add_edge_travel_times(graph)\n",
    "\n",
    "    # add edge travel times to the graph\n",
    "    #graph = ox.add_edge_travel_times(G)\n",
    "\n",
    "    return graph\n",
    "\n",
    "#not in use\n",
    "#merge the existing two json files into one\n",
    "def merge_speed_data(rush_hour_path, non_rush_hour_path):\n",
    "    merged_speed_data = {}\n",
    "\n",
    "    # Load the rush hour data\n",
    "    with open(rush_hour_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            osm_id = data.get('osm_id')\n",
    "            speed = data.get('currentSpeed')\n",
    "            if osm_id and speed:\n",
    "                if osm_id not in merged_speed_data:\n",
    "                    merged_speed_data[osm_id] = [float(speed)]\n",
    "                else:\n",
    "                    merged_speed_data[osm_id].append(float(speed))\n",
    "\n",
    "    # Load the non-rush hour data\n",
    "    with open(non_rush_hour_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            osm_id = data.get('osm_id')\n",
    "            speed = data.get('currentSpeed')\n",
    "            if osm_id and speed:\n",
    "                if osm_id not in merged_speed_data:\n",
    "                    merged_speed_data[osm_id] = [float(speed)]\n",
    "                else:\n",
    "                    merged_speed_data[osm_id].append(float(speed))\n",
    "\n",
    "    # Calculate the average speed for each osm_id\n",
    "    average_speed_data = {}\n",
    "    for osm_id, speeds in merged_speed_data.items():\n",
    "        average_speed = sum(speeds) / len(speeds)\n",
    "        average_speed_data[osm_id] = average_speed\n",
    "\n",
    "    # Return the average speed data as a JSON string\n",
    "    return json.dumps(average_speed_data)\n",
    "\n",
    "#not in use\n",
    "def loadGraph_v0(graphml_file=\"hongkong_speed.graphml\"):\n",
    "    # Define the file paths for the TomTom speed data\n",
    "    rush_hour_path = './tomtom_speeds_weekday_rush_hours.json'\n",
    "    non_rush_hour_path = './tomtom_speeds_weekday_non_rush_hours.json'\n",
    "\n",
    "    # Define the start and end times for the two rush hour intervals\n",
    "    rush_start_time_am = datetime.time(7, 0)   # Rush hour in the morning starts at 7:00 AM\n",
    "    rush_end_time_am = datetime.time(10, 0)    # Rush hour in the morning ends at 10:00 AM\n",
    "    rush_start_time_pm = datetime.time(17, 0)  # Rush hour in the evening starts at 5:00 PM\n",
    "    rush_end_time_pm = datetime.time(20, 0)    # Rush hour in the evening ends at 8:00 PM\n",
    "\n",
    "    # Load the TomTom speed data from the JSON files\n",
    "    with open(rush_hour_path) as f:\n",
    "        rush_hour_data = json.load(f)\n",
    "    with open(non_rush_hour_path) as f:\n",
    "        non_rush_hour_data = json.load(f)\n",
    "\n",
    "    # Merge the rush hour and non-rush hour data into a single dictionary\n",
    "    merged_speed_data = {**rush_hour_data, **non_rush_hour_data}\n",
    "\n",
    "    # Create a dictionary to store the average speed for each road type\n",
    "    road_type_speeds = {'FRC0': 0, 'FRC1': 0, 'FRC2': 0, 'FRC3': 0, 'FRC4': 0, 'FRC5': 0, 'FRC6': 0, 'FRC7': 0}\n",
    "\n",
    "    # Compute the average speed for each road type\n",
    "    for road_type, speeds in merged_speed_data.items():\n",
    "        total_speed = 0\n",
    "        count = 0\n",
    "        for speed in speeds:\n",
    "            time = datetime.datetime.strptime(speed['measurementTime'], '%Y-%m-%dT%H:%M:%SZ').time()\n",
    "            if (time >= rush_start_time_am and time <= rush_end_time_am) or (time >= rush_start_time_pm and time <= rush_end_time_pm):\n",
    "                # This is rush hour traffic\n",
    "                total_speed += speed['speed']\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            # There were measurements during rush hour\n",
    "            average_speed = total_speed / count\n",
    "            road_type_speeds[road_type] = average_speed\n",
    "\n",
    "    # Load the road network from the GraphML file\n",
    "    G = ox.load_graphml(graphml_file)\n",
    "\n",
    "    # Add the average speeds to the edges in the road network\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        road_type = data['FRC']\n",
    "        if road_type in road_type_speeds:\n",
    "            data['speed'] = road_type_speeds.get(road_type, 0)\n",
    "\n",
    "    return G\n",
    "#===================================================================================================\n",
    "#===================================================================================================\n",
    "#===================================================================================================\n",
    "#graph = loadGraph(\"HK\", \"travel_time\", \"drive\", hwy_speeds)\n",
    "#===================================================================================================\n",
    "#===================================================================================================\n",
    "#===================================================================================================\n",
    "\n",
    "def shortestRoute(graph, orig:(float, float), dest:(float, float), optimizer=\"travel_time\"):\n",
    "    orig_node = ox.nearest_nodes(graph, orig[1], orig[0])\n",
    "    dest_node = ox.nearest_nodes(graph, dest[1], dest[0])\n",
    "\n",
    "    try:\n",
    "        result = nx.shortest_path(graph, orig_node, dest_node, weight=optimizer)\n",
    "        #return nx.shortest_path(graph, orig_node, dest_node, weight=optimizer)\n",
    "    except Exception:\n",
    "        #return nx.shortest_path(graph, dest_node, orig_node, weight=optimizer)\n",
    "        \n",
    "        #print(\"Entered in function shortestRoute - except\")\n",
    "        result = nx.shortest_path(graph, dest_node, orig_node, weight=optimizer)\n",
    "        #print(\"orig and dest position exchanged\")\n",
    "    #result = nx.shortest_path(graph, orig_node, dest_node, weight=optimizer)\n",
    "\n",
    "    return result\n",
    "\n",
    "def routeTimeForPrinting(graph, shortest_route, optimizer=\"travel_time\"):\n",
    "    route_time = int(sum(ox.utils_graph.get_route_edge_attributes(graph, shortest_route, optimizer)))/60\n",
    "    if route_time < 60:\n",
    "        expression = str(int(route_time)) + \" mins\"\n",
    "    elif route_time < 60*24:\n",
    "        expression = str(int(route_time/60)) + \" hours \" + str(int(route_time) - int(route_time/60)*60) + \" mins\"\n",
    "    return expression\n",
    "\n",
    "def routeLength(graph, shortest_route):\n",
    "    #return nx.shortest_path_length(G=graph, source=orig_node, target=dest_node, weight=weight)/1000\n",
    "    return int(sum(ox.utils_graph.get_route_edge_attributes(graph, shortest_route, \"length\")))/1000\n",
    "\n",
    "def routeTime(graph, shortest_route):\n",
    "    return int(sum(ox.utils_graph.get_route_edge_attributes(graph, shortest_route, \"travel_time\")))/60\n",
    "    #return int(sum(ox.utils_graph.get_route_edge_attributes(graph, shortest_route, optimizer)))/60\n",
    "\n",
    "def tunnelTest(nodes: int):\n",
    "    if 582593392 in nodes or 587640136 in nodes:\n",
    "        expression = \"Cross Harbour Tunnel\"\n",
    "    else: expression = \"None\"\n",
    "    return expression\n",
    "# Tunnel Fees\n",
    "# https://www.td.gov.hk/mini_site/atd/2020/en/section4_t_2.html\n",
    "\n",
    "def getDepotFromDf(df):\n",
    "    depot = df['origLoc'].mode()[0]\n",
    "    return depot\n",
    "#It should come from the only value from \"origLoc\"\n",
    "#However, to avoid error, we add this function to secure the depot to be only one value\n",
    "\n",
    "def tspSolver(df):\n",
    "    return df\n",
    "#this function would return the arrangement of a series of nodes\n",
    "\n",
    "def getDistanceMatrix_backup(df, optimizer = \"length\"):\n",
    "\n",
    "    distanceMatrix = []\n",
    "\n",
    "    for orig in range(1, len(df)+1):\n",
    "        distances = []\n",
    "        for dest in range(1, len(df)+1):\n",
    "            orig_lnglat = (float(df[\"destLoc\"][orig].split(\",\")[0]), float(df[\"destLoc\"][orig].split(\",\")[1]))\n",
    "            dest_lnglat = (float(df[\"destLoc\"][dest].split(\",\")[0]), float(df[\"destLoc\"][dest].split(\",\")[1]))\n",
    "            distance = routeLength_for_distMatrix(graph, orig_lnglat, dest_lnglat, \"length\")\n",
    "            #print(orig_lnglat, \"&\", dest_lnglat, \"@\", distance)\n",
    "            distances.append(distance)\n",
    "        distanceMatrix.append(distances)\n",
    "\n",
    "    return distanceMatrix\n",
    "\n",
    "#check duplicate\n",
    "def removeDupRoutes(routes, simRatio):\n",
    "    paths = []\n",
    "    for route in routes:\n",
    "        path = list(route)\n",
    "        if path not in paths: paths.append(list(route))\n",
    "\n",
    "    for route_1 in range(len(paths)):\n",
    "        for route_2 in range(route_1+1, len(paths)):\n",
    "            similarity = difflib.SequenceMatcher(None, paths[route_1], paths[route_2])\n",
    "            if (similarity.ratio() > simRatio) and (similarity.ratio()<1):\n",
    "                paths[route_2] = []\n",
    "\n",
    "    return [x for x in paths if x]\n",
    "\n",
    "def loadGraph(place, optimizer=\"travel_time\", mode = \"drive\", hwy_speeds=hwy_speeds):\n",
    "    ox.config(log_console = True, use_cache = True)\n",
    "    #mode = 'drive' # 'drive', 'bike', 'walk'\n",
    "    graph = ox.graph_from_place(place, network_type = mode)\n",
    "    graph = ox.add_edge_speeds(graph, hwy_speeds)\n",
    "    graph = ox.add_edge_travel_times(graph)\n",
    "    return graph\n",
    "\n",
    "def lngLatStrToFloat(point):\n",
    "    lng = point.split(\",\")[0]\n",
    "    lat = point.split(\",\")[1]\n",
    "    return (float(lng), float(lat))\n",
    "\n",
    "#-----------------------\n",
    "#Ortools\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "def randomColorGenerator(df):\n",
    "    number_of_colors = len(df)\n",
    "    colors = [\"#\"+''.join([random.choice('0123456789ABCD') for j in range(2)])+''.join([random.choice('0123456789') for j in range(2)])\n",
    "        +''.join([random.choice('0123456789ABCDEF') for j in range(2)]) for i in range(number_of_colors)]\n",
    "    return colors\n",
    "\n",
    "def routeLength_for_distMatrix(graph, orig, dest, weight):\n",
    "    orig_node = ox.nearest_nodes(graph, orig[1], orig[0])\n",
    "    dest_node = ox.nearest_nodes(graph, dest[1], dest[0])\n",
    "    return nx.shortest_path_length(G=graph, source=orig_node, target=dest_node, weight=weight)/1000\n",
    "\n",
    "#global shortestRouteMap, shortestRouteLength, shortestRouteTime\n",
    "\n",
    "#shortestRouteMap = shortestRouteLength = shortestRouteTime = 0\n",
    "\n",
    "def VRP(graph, solution_list):\n",
    "#in use    \n",
    "    #define global variables\n",
    "    #global shortestRouteMap, shortestRouteLength, shortestRouteTime\n",
    "    shortest_RouteMap = shortest_RouteLength = shortest_RouteTime = 0\n",
    "\n",
    "    colors = randomColorGenerator(solution_list)\n",
    "\n",
    "    for node in range(len(solution_list)):\n",
    "        route_length = route_time = 0\n",
    "        if node == 0:\n",
    "            #To skip the first node(depot)\n",
    "            previous_node = node\n",
    "            #continue\n",
    "        #print(lngLatStrToFloat(solution_list[previous_node]), lngLatStrToFloat(solution_list[node]))\n",
    "        \n",
    "        if node == 1:\n",
    "            #Initialise the map (Defining the map)\n",
    "            shortest_route = shortestRoute(graph, lngLatStrToFloat(solution_list[previous_node]), lngLatStrToFloat(solution_list[node]), \"length\")\n",
    "            route_length = routeLength(graph, shortest_route)\n",
    "            route_time = routeTime(graph, shortest_route)\n",
    "            shortest_RouteMap = ox.plot_route_folium(graph, shortest_route, tiles='openstreetmap', color = colors[node])\n",
    "            #popup_node = node\n",
    "        elif solution_list[previous_node] != solution_list[node] and node!=0:\n",
    "            shortest_route = shortestRoute(graph, lngLatStrToFloat(solution_list[previous_node]), lngLatStrToFloat(solution_list[node]), \"length\")\n",
    "            route_length = routeLength(graph, shortest_route)\n",
    "            route_time = routeTime(graph, shortest_route) \n",
    "            shortest_RouteMap = ox.plot_route_folium(graph, shortest_route, route_map=shortest_RouteMap, tiles='openstreetmap', color = colors[node])\n",
    "            if solution_list[node] == solution_list[0]:\n",
    "                #If the node number is 0 means the truck is back to the depot\n",
    "            #    popup_node = \"Depot\"\n",
    "                marker = folium.Marker(location = lngLatStrToFloat(solution_list[node]), \n",
    "                                       tooltip=solution_list[node], popup=\"Depot\") #latitude,longitude\n",
    "                shortest_RouteMap.add_child(marker) \n",
    "            else: \n",
    "                #Main loop content\n",
    "            #   popup_node = node\n",
    "                marker = folium.Marker(location = lngLatStrToFloat(solution_list[node]), \n",
    "                                       tooltip=solution_list[node], popup=node) #latitude,longitude\n",
    "                shortest_RouteMap.add_child(marker) \n",
    "        #marker = folium.Marker(location = lngLatStrToFloat(solution_list[node]), tooltip=solution_list[node], popup=popup_node) #latitude,longitude\n",
    "        #shortest_RouteMap.add_child(marker) \n",
    "        #print(node, previous_node, lngLatStrToFloat(solution_list[previous_node]), lngLatStrToFloat(solution_list[node]), route_length, route_time)\n",
    "        previous_node = node\n",
    "        shortest_RouteLength += route_length\n",
    "        shortest_RouteTime += route_time\n",
    "    #print(\"VRP:\", shortest_RouteLength, shortest_RouteTime)\n",
    "    return shortest_RouteMap, shortest_RouteLength, shortest_RouteTime\n",
    "\n",
    "def routeToLngLat(df, routinglist):\n",
    "    for vehicle in range(len(routinglist)):\n",
    "        for node in range(len(routinglist[vehicle])):\n",
    "            if routinglist[vehicle][node] == 0: \n",
    "                routinglist[vehicle][node] = getDepotFromDf(df)\n",
    "            else:\n",
    "                routinglist[vehicle][node] = df[\"destLoc\"][routinglist[vehicle][node]]\n",
    "    return routinglist\n",
    "\n",
    "def decode_route(list_lnglat: list, list_order: list):\n",
    "    route_order = []\n",
    "    first_element = False\n",
    "    for order in list_order:\n",
    "        if first_element:\n",
    "            distance = ((float(route_order[-1].split(\",\")[0]) - float(list_lnglat[order].split(\",\")[0]))**2 \n",
    "                        + (float(route_order[-1].split(\",\")[1]) - float(list_lnglat[order].split(\",\")[1]))**2)**(1/2)*110.948/10\n",
    "            #print(\"distance:\", distance)\n",
    "            #below 100m then skip\n",
    "            #if list_lnglat[order] != route_order[-1]: route_order.append(list_lnglat[order])\n",
    "            if distance >= 0.1: route_order.append(list_lnglat[order])\n",
    "        else:\n",
    "            route_order.append(list_lnglat[order])\n",
    "            first_element = True\n",
    "    #print(\"route_order\", route_order)\n",
    "    return route_order\n",
    "\n",
    "#['22.45055, 114.01209', '22.45055, 114.01209', '22.44591, 114.03469']\n",
    "#0120\n",
    "#oln list: ['22.45055, 114.01209', '22.45055, 114.01209', '22.44591, 114.03469', '22.45055, 114.01209']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41664\\3164525533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_graph_place\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"travel_time\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"drive\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhwy_speeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#graph = loadGraph(\"hongkong_speed.graphml\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_41664\\24214754.py\u001b[0m in \u001b[0;36mloadGraph\u001b[1;34m(place, optimizer, mode, hwy_speeds)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_console\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;31m#mode = 'drive' # 'drive', 'bike', 'walk'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_place\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edge_speeds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhwy_speeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edge_travel_times\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\osmnx\\graph.py\u001b[0m in \u001b[0;36mgraph_from_place\u001b[1;34m(query, network_type, simplify, retain_all, truncate_by_edge, which_result, buffer_dist, clean_periphery, custom_filter)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;31m# create graph using this polygon(s) geometry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     G = graph_from_polygon(\n\u001b[0m\u001b[0;32m    352\u001b[0m         \u001b[0mpolygon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[0mnetwork_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\osmnx\\graph.py\u001b[0m in \u001b[0;36mgraph_from_polygon\u001b[1;34m(polygon, network_type, simplify, retain_all, truncate_by_edge, clean_periphery, custom_filter)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# nodes outside the poly if the way (that is, a way with a single OSM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;31m# ID) has a node inside the poly at some point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mG_buff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncate_graph_polygon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_buff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_buff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncate_by_edge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;31m# simplify the graph topology\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\osmnx\\truncate.py\u001b[0m in \u001b[0;36mtruncate_graph_polygon\u001b[1;34m(G, polygon, retain_all, truncate_by_edge, quadrat_width, min_num)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;31m# first identify all nodes whose point geometries lie within the polygon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mgs_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_to_gdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"geometry\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     \u001b[0mto_keep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils_geo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intersect_index_quadrats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquadrat_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto_keep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\osmnx\\utils_geo.py\u001b[0m in \u001b[0;36m_intersect_index_quadrats\u001b[1;34m(geometries, polygon, quadrat_width, min_num)\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[0mpossible_matches_iloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mpossible_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeometries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossible_matches_iloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mprecise_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpossible_matches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossible_matches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m             \u001b[0mgeoms_in_poly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecise_matches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\geopandas\\base.py\u001b[0m in \u001b[0;36mintersects\u001b[1;34m(self, other, align)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         \u001b[0mGeoSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m         \"\"\"\n\u001b[1;32m-> 1493\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_binary_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"intersects\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moverlaps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\geopandas\\base.py\u001b[0m in \u001b[0;36m_binary_op\u001b[1;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# type: (str, GeoSeries, GeoSeries, args/kwargs) -> Series[bool/float]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;34m\"\"\"Binary operation on GeoSeries objects that returns a Series\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_delegate_binary_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\geopandas\\base.py\u001b[0m in \u001b[0;36m_delegate_binary_method\u001b[1;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_this\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\geopandas\\array.py\u001b[0m in \u001b[0;36mintersects\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mintersects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_binary_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"intersects\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moverlaps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\geopandas\\array.py\u001b[0m in \u001b[0;36m_binary_method\u001b[1;34m(op, left, right, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcovers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\geopandas\\_vectorized.py\u001b[0m in \u001b[0;36mintersects\u001b[1;34m(data, other)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mintersects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUSE_SHAPELY_20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUSE_PYGEOS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_binary_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"intersects\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\shapely\\decorators.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marray_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_flag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_flags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tsang\\anaconda3\\lib\\site-packages\\shapely\\predicates.py\u001b[0m in \u001b[0;36mintersects\u001b[1;34m(a, b, **kwargs)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \"\"\"\n\u001b[1;32m--> 798\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph = loadGraph(load_graph_place, \"travel_time\", \"drive\", hwy_speeds)\n",
    "#graph = loadGraph(\"hongkong_speed.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistanceMatrix(routelist, optimizer = \"length\"):\n",
    "\n",
    "    #nodes = result = list(getDepotFromDf(df).split(\"-\"))\n",
    "    #for i in df[\"destLoc\"]:\n",
    "    #    nodes.append(i)\n",
    "    routeList = routelist[:len(routelist)]\n",
    "    distanceMatrix = []\n",
    "\n",
    "    for orig in routeList:\n",
    "        distances = []\n",
    "        for dest in routeList:\n",
    "            if orig == dest: \n",
    "                distances.append(0)\n",
    "                continue\n",
    "            else:\n",
    "                orig_lnglat = (float(orig.split(\",\")[0]), float(orig.split(\",\")[1]))\n",
    "                dest_lnglat = (float(dest.split(\",\")[0]), float(dest.split(\",\")[1]))\n",
    "                shortest_route = shortestRoute(graph, orig_lnglat, dest_lnglat)\n",
    "                #distance = routeLength_for_distMatrix(graph, orig_lnglat, dest_lnglat, \"length\")\n",
    "                distance = routeLength(graph, shortest_route)\n",
    "                shortest_route = 0\n",
    "            #print(orig_lnglat, \"&\", dest_lnglat, \"@\", distance)\n",
    "            distances.append(distance)\n",
    "        distanceMatrix.append(distances)\n",
    "    return distanceMatrix\n",
    "\n",
    "#ortool testing\n",
    "\"\"\"Simple Vehicles Routing Problem (VRP).\n",
    "\n",
    "   This is a sample using the routing library python wrapper to solve a VRP\n",
    "   problem.\n",
    "   A description of the problem can be found here:\n",
    "   http://en.wikipedia.org/wiki/Vehicle_routing_problem.\n",
    "\n",
    "   Distances are in meters.\n",
    "\"\"\"\n",
    "\n",
    "def create_data_model(list):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    data = {}\n",
    "    data['distance_matrix'] = getDistanceMatrix(list, \"length\")\n",
    "    \n",
    "    data['num_vehicles'] = 1\n",
    "    data['depot'] = 0\n",
    "    return data\n",
    "\n",
    "def print_solution(data, manager, routing, solution):\n",
    "    \"\"\"Prints solution on console.\"\"\"\n",
    "    #print(f'Objective: {solution.ObjectiveValue()}')\n",
    "    max_route_distance = 0\n",
    "    routingSol = []\n",
    "    for vehicle_id in range(data['num_vehicles']):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        #plan_output = 'Route for vehicle {}:\\n'.format(vehicle_id)\n",
    "        route_distance = 0\n",
    "\n",
    "        routeSol = []\n",
    "        while not routing.IsEnd(index):\n",
    "            #plan_output += ' {} -> '.format(manager.IndexToNode(index))\n",
    "            routeSol.append(manager.IndexToNode(index))\n",
    "            previous_index = index\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "            route_distance += routing.GetArcCostForVehicle(\n",
    "                previous_index, index, vehicle_id)\n",
    "        #plan_output += '{}\\n'.format(manager.IndexToNode(index))\n",
    "        routeSol.append(manager.IndexToNode(index))\n",
    "        #plan_output += 'Distance of the route: {}m\\n'.format(route_distance)\n",
    "        #print(plan_output)\n",
    "        routingSol.append(routeSol)\n",
    "        #routingSol.append(plan_output)\n",
    "        max_route_distance = max(route_distance, max_route_distance)\n",
    "    #print('Maximum of the route distances: {}m'.format(max_route_distance))\n",
    "    return routingSol[0]\n",
    "\n",
    "def get_routes(solution, routing, manager):\n",
    "  \"\"\"Get vehicle routes from a solution and store them in an array.\"\"\"\n",
    "  # Get vehicle routes and store them in a two dimensional array whose\n",
    "  # i,j entry is the jth location visited by vehicle i along its route.\n",
    "  routes = []\n",
    "  for route_nbr in range(routing.vehicles()):\n",
    "    index = routing.Start(route_nbr)\n",
    "    route = [manager.IndexToNode(index)]\n",
    "    while not routing.IsEnd(index):\n",
    "      index = solution.Value(routing.NextVar(index))\n",
    "      route.append(manager.IndexToNode(index))\n",
    "    routes.append(route)\n",
    "  return routes\n",
    "\n",
    "def ortool(list):\n",
    "    \"\"\"Entry point of the program.\"\"\"\n",
    "    # Instantiate the data problem.\n",
    "    data = create_data_model(list)\n",
    "    result = []\n",
    "\n",
    "    # Create the routing index manager.\n",
    "    manager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),\n",
    "                                           data['num_vehicles'], data['depot'])\n",
    "\n",
    "    # Create Routing Model.\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "\n",
    "    # Create and register a transit callback.\n",
    "    def distance_callback(from_index, to_index):\n",
    "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
    "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return data['distance_matrix'][from_node][to_node]\n",
    "\n",
    "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "\n",
    "    # Define cost of each arc.\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "    # Add Distance constraint.\n",
    "    dimension_name = 'Distance'\n",
    "    routing.AddDimension(\n",
    "        transit_callback_index,\n",
    "        0,  # no slack\n",
    "        300000,  # vehicle maximum travel distance\n",
    "        True,  # start cumul to zero\n",
    "        dimension_name)\n",
    "    distance_dimension = routing.GetDimensionOrDie(dimension_name)\n",
    "    distance_dimension.SetGlobalSpanCostCoefficient(100)\n",
    "\n",
    "    # Setting first solution heuristic.\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "\n",
    "    # Solve the problem.\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    # Print solution on console.\n",
    "    if solution:\n",
    "        result = print_solution(data, manager, routing, solution)\n",
    "    else:\n",
    "        print('No solution found !')\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #resultingSol = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear the route that contains the point outside hong kong\n",
    "#str = '22.1504, 113.55207'\n",
    "\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "invalid_routes = []\n",
    "\n",
    "for idx, row in raw_clean.iterrows():\n",
    "    points = row['Route']\n",
    "    inside = True\n",
    "    for point in points:\n",
    "        is_inside_hong_kong = hong_kong_boundary.contains(Point(float(point.split(\",\")[0]), float(point.split(\",\")[1])))\n",
    "        if is_inside_hong_kong == False:\n",
    "            inside = False\n",
    "            break\n",
    "    if inside == False:\n",
    "        invalid_routes.append(idx)\n",
    "\n",
    "raw_clean = raw_clean[~raw_clean.index.isin(invalid_routes)]\n",
    "raw_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_clean.to_csv(\"check_before_routing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "distances = []\n",
    "times = []\n",
    "maps = []\n",
    "journey_orders = []\n",
    "#print(\"length=\", len(raw_clean))\n",
    "\n",
    "for idx, row in tqdm(raw_clean.iterrows(), total=len(raw_clean)):\n",
    "    journey = row[\"Route\"]\n",
    "    route_order = ortool(journey)\n",
    "    journey_order = decode_route(journey, route_order)\n",
    "    shortestRouteMap, shortestRouteLength, shortestRouteTime = VRP(graph, journey_order)\n",
    "    journey_orders.append(journey_order)\n",
    "    distances.append(shortestRouteLength)\n",
    "    times.append(shortestRouteTime)\n",
    "    maps.append(shortestRouteMap)\n",
    "    #print(\"idx:\", idx, shortestRouteLength, shortestRouteTime)\n",
    "\n",
    "df_journey_orders = pd.DataFrame({\"Route_Order\":journey_orders})\n",
    "df_distances = pd.DataFrame({\"Distances\":distances})\n",
    "df_times = pd.DataFrame({\"Time\":times})\n",
    "df_maps = pd.DataFrame({\"Maps\":maps})\n",
    "\n",
    "raw_clean = raw_clean.reset_index()\n",
    "raw_clean = raw_clean.assign(Route_Order=df_journey_orders[\"Route_Order\"],\n",
    "                             Distances=df_distances[\"Distances\"],\n",
    "                             Time=df_times[\"Time\"],\n",
    "                             Maps=df_maps[\"Maps\"])\n",
    "raw_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_clean.to_csv(check_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather handling\n",
    "#download from https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Set Pandas options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Read the weather data file into a dataframe\n",
    "df_weather_hk = pd.read_csv(weather_file_name)\n",
    "\n",
    "# Select the desired columns and merge the latitude and longitude columns into a point\n",
    "df_weather_hk = df_weather_hk[[\"STATION\", \"DATE\", \"NAME\", \"LATITUDE\", \"LONGITUDE\", \"TEMP\", \"DEWP\", \"VISIB\", \"WDSP\", \"MXSPD\", \"GUST\", \"MAX\", \"MIN\", \"PRCP\", \"SNDP\", \"FRSHTT\"]]\n",
    "df_weather_hk[\"POINT\"] = df_weather_hk.apply(lambda row: Point(row['LONGITUDE'], row['LATITUDE']), axis=1)\n",
    "\n",
    "# Replace 999.9 values in GUST column with 0\n",
    "df_weather_hk.loc[df_weather_hk[\"GUST\"] == 999.9, \"GUST\"] = 0\n",
    "\n",
    "# Replace 99.9 values in PRCP column with 0\n",
    "df_weather_hk.loc[df_weather_hk[\"PRCP\"] == 99.9, \"PRCP\"] = 0\n",
    "\n",
    "# Replace 999.9 values in SNDP column with 0\n",
    "df_weather_hk.loc[df_weather_hk[\"SNDP\"] == 999.9, \"SNDP\"] = 0\n",
    "\n",
    "# Convert FRSHTT column to string and fill 0 at the front if necessary\n",
    "df_weather_hk[\"FRSHTT\"] = df_weather_hk[\"FRSHTT\"].astype(str).str.zfill(6)\n",
    "\n",
    "# Split FRSHTT column into 6 separate columns with proper naming\n",
    "df_weather_hk = pd.concat([df_weather_hk, df_weather_hk[\"FRSHTT\"].apply(lambda x: pd.Series(list(x)))], axis=1)\n",
    "df_weather_hk = df_weather_hk.rename(columns={0: \"FOG_MIST\", 1: \"PRECIP_DRIZZLE\", 2: \"HAIL_SLEET\", 3: \"THUNDER\", 4: \"TORNADO_FUNNEL_CLOUD\", 5: \"WIND_DAMAGE\"})\n",
    "\n",
    "# Drop the original FRSHTT column and the LATITUDE and LONGITUDE columns\n",
    "df_weather_hk = df_weather_hk.drop(columns=[\"FRSHTT\", \"LATITUDE\", \"LONGITUDE\"])\n",
    "\n",
    "# Modify the NAME column as requested\n",
    "df_weather_hk[\"NAME\"] = df_weather_hk[\"NAME\"].apply(lambda x: \"HONG KONG\" if x == \"HONG KONG INTERNATIONAL, HK\" else x)\n",
    "\n",
    "# Drop any rows where the NAME column is not equal to \"HONG KONG INTERNATIONAL, HK\"\n",
    "df_weather_hk = df_weather_hk[df_weather_hk[\"NAME\"] == \"HONG KONG\"]\n",
    "\n",
    "# Convert STATION column to string and keep only the first five digits\n",
    "df_weather_hk[\"STATION\"] = df_weather_hk[\"STATION\"].astype(str).str[:5]\n",
    "\n",
    "# Move the POINT column to be right after the STATION column\n",
    "cols = list(df_weather_hk.columns)\n",
    "cols.remove(\"POINT\")\n",
    "cols.insert(cols.index(\"STATION\")+1, \"POINT\")\n",
    "df_weather_hk = df_weather_hk.reindex(columns=cols)\n",
    "\n",
    "# Reorder the columns to have DATE, NAME, STATION, POINT, and then the remaining columns\n",
    "df_weather_hk = df_weather_hk[[\"DATE\", \"NAME\", \"STATION\", \"POINT\", \"TEMP\", \"DEWP\", \"VISIB\", \"WDSP\", \"MXSPD\", \"GUST\", \"MAX\", \"MIN\", \"PRCP\", \"SNDP\", \"FOG_MIST\", \"PRECIP_DRIZZLE\", \"HAIL_SLEET\", \"THUNDER\", \"TORNADO_FUNNEL_CLOUD\", \"WIND_DAMAGE\"]]\n",
    "\n",
    "# Print the resulting dataframe\n",
    "df_weather_hk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DATE column in df_weather_hk to datetime format\n",
    "df_weather_hk['DATE'] = pd.to_datetime(df_weather_hk['DATE'])\n",
    "\n",
    "# Convert planStartTime column in raw_clean to datetime format that matches DATE format\n",
    "raw_clean['planStartTime'] = pd.to_datetime(raw_clean['planStartTime'].dt.strftime('%Y-%m-%d'))\n",
    "\n",
    "# Merge raw_clean and df_weather_hk based on planStartTime and DATE columns using merge_asof()\n",
    "raw_merge = pd.merge_asof(raw_clean.sort_values('planStartTime'), df_weather_hk, left_on='planStartTime', right_on='DATE', direction='nearest')\n",
    "\n",
    "# Drop the unused columns\n",
    "raw_merge = raw_merge.drop(columns=['DATE', 'NAME', 'STATION', 'POINT'])\n",
    "\n",
    "# Print the resulting dataframe\n",
    "raw_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "raw_merge.to_csv(final_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f81e86336cba2bb42556008b43b6f97d730965312b223ea6defcc86e35685e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
