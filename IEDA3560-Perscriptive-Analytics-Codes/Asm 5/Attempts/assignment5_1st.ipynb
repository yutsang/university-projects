{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment-5\n",
    "\n",
    "Your main task for this assignment is to combine Linear Regression, Greedy Algorithm and PnL discussed in lecture to predict your trading results. You will be predicting Bitcoin price this time. You should refer to the ipynb file for this tutorial to get the structure. \n",
    "\n",
    "This time the prediction will be slightly different from the Lab. Every prediction should be a result from a model that is trained based on the previous 400 days. Example: if you are predicting 1-1-2019, the model should be trained using the previous 400 days, and so on.\n",
    "\n",
    "\n",
    "The instruction to the assignment are as follow:\n",
    "\n",
    "1. Read BTC price data\n",
    "2. Only keep `close` column for analysis.\n",
    "3. Create features that correspond to the time interval in which we want to predict\n",
    "4. Drop all rows with missing value.\n",
    "5. Set `fix_history_length` equal to 400, `fix_test_length` equal to 100\n",
    "6. Use Greedy Algorithm instead of All Subset Selection\n",
    "7. Find 50 different samples of Return using the given seed format\n",
    "8. Use a histogram to summarize your result. Make sure to adjust the histogram settings to make it look nice\n",
    "\n",
    "The total running time should be about 7 hours. Do not shut down your kernel during the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages\n",
    "#pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-07</td>\n",
       "      <td>272.559998</td>\n",
       "      <td>278.250000</td>\n",
       "      <td>269.410004</td>\n",
       "      <td>274.910004</td>\n",
       "      <td>274.910004</td>\n",
       "      <td>16708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>274.910004</td>\n",
       "      <td>278.779999</td>\n",
       "      <td>271.309998</td>\n",
       "      <td>274.489990</td>\n",
       "      <td>274.489990</td>\n",
       "      <td>13902830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>274.489990</td>\n",
       "      <td>293.260010</td>\n",
       "      <td>273.790009</td>\n",
       "      <td>290.019989</td>\n",
       "      <td>290.019989</td>\n",
       "      <td>43259194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-10</td>\n",
       "      <td>290.019989</td>\n",
       "      <td>300.959991</td>\n",
       "      <td>288.119995</td>\n",
       "      <td>291.369995</td>\n",
       "      <td>291.369995</td>\n",
       "      <td>46657647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-11</td>\n",
       "      <td>291.369995</td>\n",
       "      <td>297.660004</td>\n",
       "      <td>288.880005</td>\n",
       "      <td>295.600006</td>\n",
       "      <td>295.600006</td>\n",
       "      <td>23542829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>3842.939941</td>\n",
       "      <td>3853.280029</td>\n",
       "      <td>3788.040039</td>\n",
       "      <td>3812.310059</td>\n",
       "      <td>3812.310059</td>\n",
       "      <td>64065044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>3812.310059</td>\n",
       "      <td>3831.010010</td>\n",
       "      <td>3705.139893</td>\n",
       "      <td>3731.280029</td>\n",
       "      <td>3731.280029</td>\n",
       "      <td>147245676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>3731.280029</td>\n",
       "      <td>3893.520020</td>\n",
       "      <td>3720.489990</td>\n",
       "      <td>3874.179932</td>\n",
       "      <td>3874.179932</td>\n",
       "      <td>165062256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>3874.179932</td>\n",
       "      <td>3916.290039</td>\n",
       "      <td>3839.389893</td>\n",
       "      <td>3874.979980</td>\n",
       "      <td>3874.979980</td>\n",
       "      <td>129520549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>3874.979980</td>\n",
       "      <td>3911.760010</td>\n",
       "      <td>3853.199951</td>\n",
       "      <td>3882.610107</td>\n",
       "      <td>3882.610107</td>\n",
       "      <td>146201726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     2015-03-07   272.559998   278.250000   269.410004   274.910004   \n",
       "1     2015-03-08   274.910004   278.779999   271.309998   274.489990   \n",
       "2     2015-03-09   274.489990   293.260010   273.790009   290.019989   \n",
       "3     2015-03-10   290.019989   300.959991   288.119995   291.369995   \n",
       "4     2015-03-11   291.369995   297.660004   288.880005   295.600006   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1457  2019-03-03  3842.939941  3853.280029  3788.040039  3812.310059   \n",
       "1458  2019-03-04  3812.310059  3831.010010  3705.139893  3731.280029   \n",
       "1459  2019-03-05  3731.280029  3893.520020  3720.489990  3874.179932   \n",
       "1460  2019-03-06  3874.179932  3916.290039  3839.389893  3874.979980   \n",
       "1461  2019-03-07  3874.979980  3911.760010  3853.199951  3882.610107   \n",
       "\n",
       "        Adj Close     Volume  \n",
       "0      274.910004   16708000  \n",
       "1      274.489990   13902830  \n",
       "2      290.019989   43259194  \n",
       "3      291.369995   46657647  \n",
       "4      295.600006   23542829  \n",
       "...           ...        ...  \n",
       "1457  3812.310059   64065044  \n",
       "1458  3731.280029  147245676  \n",
       "1459  3874.179932  165062256  \n",
       "1460  3874.979980  129520549  \n",
       "1461  3882.610107  146201726  \n",
       "\n",
       "[1462 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows, pd.options.display.max_columns = 10, 25\n",
    "BTC_price_origin = pd.read_csv('BTC-USD.csv')\n",
    "BTC_price_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Close\n",
      "2015-03-07   274.910004\n",
      "2015-03-08   274.489990\n",
      "2015-03-09   290.019989\n",
      "2015-03-10   291.369995\n",
      "2015-03-11   295.600006\n",
      "...                 ...\n",
      "2019-03-03  3812.310059\n",
      "2019-03-04  3731.280029\n",
      "2019-03-05  3874.179932\n",
      "2019-03-06  3874.979980\n",
      "2019-03-07  3882.610107\n",
      "\n",
      "[1462 rows x 1 columns]\n",
      "DatetimeIndex(['2015-03-07', '2015-03-08', '2015-03-09', '2015-03-10',\n",
      "               '2015-03-11', '2015-03-12', '2015-03-13', '2015-03-14',\n",
      "               '2015-03-15', '2015-03-16',\n",
      "               ...\n",
      "               '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01',\n",
      "               '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05',\n",
      "               '2019-03-06', '2019-03-07'],\n",
      "              dtype='datetime64[ns]', length=1462, freq=None)\n"
     ]
    }
   ],
   "source": [
    "BTC_price_origin.index = pd.to_datetime(BTC_price_origin['Date'].values, format='%Y-%m-%d')\n",
    "stock = BTC_price_origin[['Close']].copy()\n",
    "print(stock)\n",
    "print(stock.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-03-07</th>\n",
       "      <td>274.910004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-08</th>\n",
       "      <td>274.489990</td>\n",
       "      <td>-0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-09</th>\n",
       "      <td>290.019989</td>\n",
       "      <td>0.053548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-10</th>\n",
       "      <td>291.369995</td>\n",
       "      <td>0.004633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-11</th>\n",
       "      <td>295.600006</td>\n",
       "      <td>0.014310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-03</th>\n",
       "      <td>3812.310059</td>\n",
       "      <td>-0.008034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>3731.280029</td>\n",
       "      <td>-0.021716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>3874.179932</td>\n",
       "      <td>0.036885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>3874.979980</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>3882.610107</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Close    Return\n",
       "2015-03-07   274.910004       NaN\n",
       "2015-03-08   274.489990 -0.001530\n",
       "2015-03-09   290.019989  0.053548\n",
       "2015-03-10   291.369995  0.004633\n",
       "2015-03-11   295.600006  0.014310\n",
       "...                 ...       ...\n",
       "2019-03-03  3812.310059 -0.008034\n",
       "2019-03-04  3731.280029 -0.021716\n",
       "2019-03-05  3874.179932  0.036885\n",
       "2019-03-06  3874.979980  0.000206\n",
       "2019-03-07  3882.610107  0.001965\n",
       "\n",
       "[1462 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock['Return'] = stock['Close'].diff()/stock['Close']\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_variables = ['1D','3D','1W','2W','3W','1M','6W','2M','3M','4M','5M','6M','9M','1Y']\n",
    "\n",
    "target = ['Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Return</th>\n",
       "      <th>Return_1D</th>\n",
       "      <th>Return_3D</th>\n",
       "      <th>Return_1W</th>\n",
       "      <th>Return_2W</th>\n",
       "      <th>Return_3W</th>\n",
       "      <th>Return_1M</th>\n",
       "      <th>Return_6W</th>\n",
       "      <th>Return_2M</th>\n",
       "      <th>Return_3M</th>\n",
       "      <th>Return_4M</th>\n",
       "      <th>Return_5M</th>\n",
       "      <th>Return_6M</th>\n",
       "      <th>Return_9M</th>\n",
       "      <th>Return_1Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-13</th>\n",
       "      <td>333.769989</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>-0.129288</td>\n",
       "      <td>-0.036414</td>\n",
       "      <td>0.093849</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>0.014069</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.001218</td>\n",
       "      <td>0.041177</td>\n",
       "      <td>-0.009158</td>\n",
       "      <td>-0.024694</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>-0.001530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-14</th>\n",
       "      <td>331.769989</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.104952</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.041239</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>-0.013381</td>\n",
       "      <td>0.010836</td>\n",
       "      <td>-0.015732</td>\n",
       "      <td>0.053548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-15</th>\n",
       "      <td>317.450012</td>\n",
       "      <td>-0.045109</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>-0.129288</td>\n",
       "      <td>-0.047531</td>\n",
       "      <td>-0.051022</td>\n",
       "      <td>-0.009504</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>-0.004068</td>\n",
       "      <td>-0.010057</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.020325</td>\n",
       "      <td>-0.002672</td>\n",
       "      <td>0.004633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-16</th>\n",
       "      <td>330.209991</td>\n",
       "      <td>0.038642</td>\n",
       "      <td>-0.045109</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.104952</td>\n",
       "      <td>-0.034856</td>\n",
       "      <td>0.036260</td>\n",
       "      <td>0.032275</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>-0.013005</td>\n",
       "      <td>0.017704</td>\n",
       "      <td>0.038465</td>\n",
       "      <td>-0.074594</td>\n",
       "      <td>-0.003185</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>0.014310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-17</th>\n",
       "      <td>333.910004</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.038642</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>0.087285</td>\n",
       "      <td>0.039679</td>\n",
       "      <td>0.101119</td>\n",
       "      <td>0.029255</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>-0.001649</td>\n",
       "      <td>-0.002196</td>\n",
       "      <td>-0.013742</td>\n",
       "      <td>0.019972</td>\n",
       "      <td>0.016206</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>-0.005955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-03</th>\n",
       "      <td>3812.310059</td>\n",
       "      <td>-0.008034</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>-0.007237</td>\n",
       "      <td>-0.009400</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>-0.020436</td>\n",
       "      <td>0.007944</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.020414</td>\n",
       "      <td>-0.054606</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>0.013543</td>\n",
       "      <td>-0.028244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>3731.280029</td>\n",
       "      <td>-0.021716</td>\n",
       "      <td>-0.008034</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.032626</td>\n",
       "      <td>-0.021521</td>\n",
       "      <td>-0.126958</td>\n",
       "      <td>0.014030</td>\n",
       "      <td>-0.099154</td>\n",
       "      <td>0.008659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>3874.179932</td>\n",
       "      <td>0.036885</td>\n",
       "      <td>-0.021716</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>0.039903</td>\n",
       "      <td>0.061763</td>\n",
       "      <td>-0.003200</td>\n",
       "      <td>-0.017121</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.037471</td>\n",
       "      <td>-0.005177</td>\n",
       "      <td>-0.029102</td>\n",
       "      <td>-0.046036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>3874.979980</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.036885</td>\n",
       "      <td>-0.008034</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>-0.100082</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>-0.004779</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>-0.004843</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>-0.058014</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>-0.016164</td>\n",
       "      <td>0.053599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>3882.610107</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-0.021716</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.012534</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.060314</td>\n",
       "      <td>0.082527</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>-0.034131</td>\n",
       "      <td>0.028437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1211 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Close    Return  Return_1D  Return_3D  Return_1W  Return_2W  \\\n",
       "2015-11-13   333.769989 -0.000240   0.087285  -0.129288  -0.036414   0.093849   \n",
       "2015-11-14   331.769989 -0.006028  -0.000240  -0.104952   0.022776   0.010976   \n",
       "2015-11-15   317.450012 -0.045109  -0.006028   0.087285  -0.129288  -0.047531   \n",
       "2015-11-16   330.209991  0.038642  -0.045109  -0.000240  -0.104952  -0.034856   \n",
       "2015-11-17   333.910004  0.011081   0.038642  -0.006028   0.087285   0.039679   \n",
       "...                 ...       ...        ...        ...        ...        ...   \n",
       "2019-03-03  3812.310059 -0.008034   0.002982  -0.001922  -0.007237  -0.009400   \n",
       "2019-03-04  3731.280029 -0.021716  -0.008034   0.002117   0.003352   0.011671   \n",
       "2019-03-05  3874.179932  0.036885  -0.021716   0.002982  -0.001922   0.039903   \n",
       "2019-03-06  3874.979980  0.000206   0.036885  -0.008034   0.002117  -0.100082   \n",
       "2019-03-07  3882.610107  0.001965   0.000206  -0.021716   0.002982   0.019215   \n",
       "\n",
       "            Return_3W  Return_1M  Return_6W  Return_2M  Return_3M  Return_4M  \\\n",
       "2015-11-13   0.032172   0.019960   0.014069  -0.001049  -0.001218   0.041177   \n",
       "2015-11-14   0.041239   0.018412   0.008293   0.007579  -0.001656   0.019825   \n",
       "2015-11-15  -0.051022  -0.009504   0.032069   0.024336  -0.004068  -0.010057   \n",
       "2015-11-16   0.036260   0.032275   0.024891  -0.013005   0.017704   0.038465   \n",
       "2015-11-17   0.101119   0.029255  -0.030229  -0.001649  -0.002196  -0.013742   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-03-03   0.006566  -0.020436   0.007944   0.008362   0.020414  -0.054606   \n",
       "2019-03-04   0.014623   0.001678   0.013410  -0.008396  -0.032626  -0.021521   \n",
       "2019-03-05   0.061763  -0.003200  -0.017121   0.007356   0.009860  -0.000919   \n",
       "2019-03-06   0.002974  -0.004779  -0.005357  -0.004362  -0.004843   0.007022   \n",
       "2019-03-07   0.012534   0.001327   0.004763   0.003784   0.060314   0.082527   \n",
       "\n",
       "            Return_5M  Return_6M  Return_9M  Return_1Y  \n",
       "2015-11-13  -0.009158  -0.024694   0.000296  -0.001530  \n",
       "2015-11-14  -0.013381   0.010836  -0.015732   0.053548  \n",
       "2015-11-15  -0.000396  -0.020325  -0.002672   0.004633  \n",
       "2015-11-16  -0.074594  -0.003185   0.008292   0.014310  \n",
       "2015-11-17   0.019972   0.016206   0.006033  -0.005955  \n",
       "...               ...        ...        ...        ...  \n",
       "2019-03-03   0.005235  -0.002876   0.013543  -0.028244  \n",
       "2019-03-04  -0.126958   0.014030  -0.099154   0.008659  \n",
       "2019-03-05   0.037471  -0.005177  -0.029102  -0.046036  \n",
       "2019-03-06  -0.058014   0.007096  -0.016164   0.053599  \n",
       "2019-03-07   0.010044   0.007651  -0.034131   0.028437  \n",
       "\n",
       "[1211 rows x 16 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the predictor to corresponding no of days\n",
    "vardict = { '1D': 1, '3D': 3,\n",
    "            '1W': 5, '2W': 10, '3W': 15, '6W': 30,\n",
    "            '1M': 20, '2M': 40, '3M': 60, '4M': 80, '5M': 100, '6M': 120, '9M': 180,\n",
    "            '1Y': 250}\n",
    "\n",
    "for var in predictor_variables:\n",
    "    name = 'Return_' + var\n",
    "    stock[name] = stock.Return.shift(vardict[var])\n",
    "\n",
    "stock = stock.dropna()\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def all_subsets(my_list):\n",
    "    subs = []\n",
    "    for i in range(1, len(my_list) + 1):\n",
    "        subs += combinations(my_list, i)\n",
    "    subset_List = []\n",
    "    for i in subs:\n",
    "        subset_List += [list(i)]\n",
    "    return subset_List\n",
    "\n",
    "features = stock.columns.values.tolist()[2:]\n",
    "target = ['Return']\n",
    "\n",
    "features_subs = all_subsets(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_history_length = 400\n",
    "fix_test_length = 100\n",
    "sample_size = 50\n",
    "randomRange = len(stock) - fix_history_length - fix_test_length\n",
    "randomRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_algo(train_valid, target, proportion):\n",
    "    \n",
    "    # initialize a list to save features\n",
    "    greedy_select = []\n",
    "    \n",
    "    profit_greedy_algo = np.array([])\n",
    "    for i in range(len(features)):\n",
    "        profit = np.array([])\n",
    "        features_left = list(set(features) - set(greedy_select))\n",
    "\n",
    "        for new in features_left:\n",
    "            features_new = greedy_select + [new]\n",
    "            train_valid_sub = train_valid[features_new + target]\n",
    "\n",
    "            # CrossValidation, compute the profit and save it into profit_sub\n",
    "            profit_sub = PnL(train_valid_sub, target, proportion)\n",
    "            profit = np.append(profit, profit_sub)\n",
    "\n",
    "        # pick the features that gives the largest profit\n",
    "        # and add it into our features list\n",
    "        # meanwhile, save the corresponding profit\n",
    "        greedy_select += [features_left[profit.argmax()]]\n",
    "        profit_greedy_algo = np.append(profit_greedy_algo, profit.max())\n",
    "        \n",
    "    return greedy_select[:(profit_greedy_algo.argmax()+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def computation(df):\n",
    "    for i in range(1, len(df)):\n",
    "        if df.iloc[i, 1] >= 0:\n",
    "            df.iloc[i, 2] = df.iloc[i-1, 2] * (1 + df.iloc[i, 0])\n",
    "        else:\n",
    "            df.iloc[i, 2] = df.iloc[i-1, 2] * (1 - df.iloc[i, 0])\n",
    "    return df\n",
    "\n",
    "def PnL(data, target, proportion):\n",
    "    train_sub, valid_sub = train_test_split(data, test_size = proportion, random_state = 0)\n",
    "\n",
    "    # create a linear model\n",
    "    X_train = train_sub.drop(target, axis = 1)\n",
    "    Y_train = train_sub[target]\n",
    "    X_valid = valid_sub.drop(target, axis = 1)\n",
    "    Y_valid = valid_sub[target]\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_valid_fit = model.predict(X_valid)\n",
    "\n",
    "    # a data frame for computing and saving long_short value\n",
    "    long_short_df = pd.DataFrame({'Return': Y_valid.iloc[:,0].values,\n",
    "                                  'Predicted Return': Y_valid_fit.reshape(1,-1)[0].tolist(),\n",
    "                                  'Long-short value': np.zeros(len(valid_sub))},\n",
    "                                 index = valid_sub.index)\n",
    "\n",
    "    cols = ['Return', 'Predicted Return', 'Long-short value']\n",
    "    long_short_df = long_short_df[cols]\n",
    "\n",
    "    # give an initial point\n",
    "    initial = pd.DataFrame(np.array([0,0,1]).reshape(-1,3),\n",
    "                       columns = long_short_df.columns)\n",
    "\n",
    "    # combine df and initial point\n",
    "    long_short_df = pd.concat([initial, long_short_df]) \n",
    "    \n",
    "    # compute long_short value\n",
    "    long_short_df_final = computation(long_short_df)\n",
    "    \n",
    "    # return final long_short value of this period\n",
    "    return long_short_df_final.iloc[-1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12h 21min 54s, sys: 3h 36min 59s, total: 15h 58min 53s\n",
      "Wall time: 2h 40min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.36685107, 1.18038739, 1.06897017, 1.70985132, 0.89258145,\n",
       "       0.63139541, 0.83342753, 0.80349318, 1.07493998, 1.27440642,\n",
       "       0.75132336, 0.20840567, 1.1165358 , 0.67837267, 0.73029019,\n",
       "       0.67510199, 1.40911642, 1.58130451, 0.97498131, 0.75639879,\n",
       "       0.5210792 , 1.54293813, 0.90892501, 0.70720938, 0.95676926,\n",
       "       1.94423005, 1.21718828, 1.46961674, 1.1499853 , 0.30594945,\n",
       "       2.57311981, 0.70736841, 2.06166376, 1.35433106, 2.26691105,\n",
       "       1.33915904, 1.24428714, 0.74942906, 0.72082447, 0.64962772,\n",
       "       0.6237515 , 1.56156538, 0.70736841, 0.65002065, 1.48574398,\n",
       "       0.98082516, 0.66375061, 1.02255006, 1.26165354, 0.65737444])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "profit_final = np.array([])\n",
    "\n",
    "# Think about why we need two loops here:\n",
    "# The answer is that this time, we need to change the training data for each day, each sample\n",
    "# In total, we have 50 samples\n",
    "for j in range(sample_size):\n",
    "    \n",
    "    np.random.seed(j)\n",
    "\n",
    "    for i in range(fix_test_length):  \n",
    "        \n",
    "        random_Num = np.random.randint(randomRange)\n",
    "        BeginTime = random_Num\n",
    "        timestamp = fix_history_length + random_Num\n",
    "        EndTime = timestamp + fix_test_length\n",
    "\n",
    "        train_valid = stock.iloc[BeginTime:timestamp, : ]\n",
    "        test = stock.iloc[timestamp:EndTime, : ]\n",
    "\n",
    "        feature_update = greedy_algo(train_valid, target, 0.2)\n",
    "\n",
    "        X_cv = train_valid[feature_update]\n",
    "        Y_cv = train_valid[target]\n",
    "\n",
    "        X_test_cv = test[feature_update]\n",
    "        Y_test_cv = test[target]\n",
    "\n",
    "        model_cv = linear_model.LinearRegression()\n",
    "        model_cv.fit(X_cv, Y_cv)\n",
    "\n",
    "        Y_test_cv_fit = model_cv.predict(X_test_cv)\n",
    "\n",
    "        long_short_df = pd.DataFrame({'Return': Y_test_cv.values.reshape(1,-1)[0].tolist(),\n",
    "                                      'Predicted Return': Y_test_cv_fit.reshape(1,-1)[0].tolist(),\n",
    "                                      'Long-short value': np.zeros(len(Y_test_cv))},\n",
    "                                     index = Y_test_cv.index)\n",
    "\n",
    "        cols = ['Return', 'Predicted Return', 'Long-short value']\n",
    "        long_short_df = long_short_df[cols]\n",
    "\n",
    "        initial = pd.DataFrame(np.array([0,0,1]).reshape(-1,3),\n",
    "                               columns = long_short_df.columns)\n",
    "        \n",
    "        long_short_df = pd.concat([initial, long_short_df])\n",
    "        long_short_df_final = computation(long_short_df)\n",
    "    \n",
    "    profit_final = np.append(profit_final,long_short_df_final.iloc[-1,2])\n",
    "\n",
    "profit_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.3, 14, '100 test points')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "bins = np.linspace(0.3, 1.7, 15)\n",
    "a = plt.hist(profit_final, bins, histtype='bar', rwidth=0.9)\n",
    "for i in range(len(bins)-1):\n",
    "    plt.text(a[1][i]+0.037,a[0][i]+0.2,int(a[0][i]))\n",
    "plt.title(\"histogram of 50 Returns for cryptocurrency--'Bitcoin'\")\n",
    "\n",
    "# you should change the coordinates of the plot to make it look nice\n",
    "plt.text(0.3, 18, (\"Avg Return: {0:.2f}%\".format((profit_final.mean()-1) * 100)))\n",
    "plt.text(0.3, 17, (\"Std dev: {0:.2f}%\".format(profit_final.std() * 100)))\n",
    "plt.text(0.3, 16, \"320 training points\")\n",
    "plt.text(0.3, 15, \"80 validation points\")\n",
    "plt.text(0.3, 14, \"100 test points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
